{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f0b5b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = r\"C:\\Users\\nbxyz\\Desktop\\image-caption-generate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c127a19",
   "metadata": {},
   "source": [
    "# prepare image input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a9b073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "#load Inception model for transfer learning\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21feffec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01f307c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "#get features using inception model\n",
    "base_model = InceptionV3(weights='imagenet',\n",
    "                         input_shape=(299, 299, 3), pooling=max)\n",
    "model = Model(base_model.input, base_model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "859ad920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add to memory\n",
    "def process_img(img_path):\n",
    "    with tf.device('/GPU:0'):\n",
    "        #load with size 299 x 299 as inception_v2 accept that\n",
    "        img = load_img(img_path, target_size=(299, 299, 3))\n",
    "        img_arr = img_to_array(img)\n",
    "        #expand by a dimension and scale pixels from -1 to 1 range\n",
    "        img_arr = np.expand_dims(img_arr, axis=0)\n",
    "        img_arr = preprocess_input(img_arr)\n",
    "        return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7a15917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_feature(img_arr):\n",
    "    with tf.device('/GPU:0'):\n",
    "        feature_vec = model.predict(img_arr)\n",
    "        feature_vec = np.reshape(feature_vec, (feature_vec.shape[1]))\n",
    "        return feature_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24347812",
   "metadata": {},
   "source": [
    "# gui for drag and drop image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac49a604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QLabel, QVBoxLayout, QMessageBox\n",
    "from PyQt5.QtCore import Qt\n",
    "from PyQt5.QtGui import QPixmap\n",
    "\n",
    "\n",
    "class ImageLabel(QLabel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.setAlignment(Qt.AlignCenter)\n",
    "        self.setText('\\n\\n Drop Image Here \\n\\n')\n",
    "        self.setStyleSheet('''\n",
    "            QLabel{\n",
    "                border: 4px dashed #aaa\n",
    "            }\n",
    "        ''')\n",
    "\n",
    "    def setPixmap(self, image):\n",
    "        super().setPixmap(image)\n",
    "\n",
    "class AppDemo(QWidget):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.img_path = ''\n",
    "        self.resize(400, 400)\n",
    "        self.setAcceptDrops(True)\n",
    "\n",
    "        mainLayout = QVBoxLayout()\n",
    "\n",
    "        self.photoViewer = ImageLabel()\n",
    "        mainLayout.addWidget(self.photoViewer)\n",
    "\n",
    "        self.setLayout(mainLayout)\n",
    "\n",
    "    def dragEnterEvent(self, event):\n",
    "        if event.mimeData().hasImage:\n",
    "            event.accept()\n",
    "        else:\n",
    "            event.ignore()\n",
    "\n",
    "    def dragMoveEvent(self, event):\n",
    "        if event.mimeData().hasImage:\n",
    "            event.accept()\n",
    "        else:\n",
    "            event.ignore()\n",
    "\n",
    "    def dropEvent(self, event):\n",
    "        if event.mimeData().hasImage:\n",
    "            event.setDropAction(Qt.CopyAction)\n",
    "            file_path = event.mimeData().urls()[0].toLocalFile()\n",
    "            self.set_path(file_path)\n",
    "            self.set_image(file_path)\n",
    "\n",
    "            event.accept()\n",
    "        else:\n",
    "            event.ignore()\n",
    "\n",
    "    def set_image(self, file_path):\n",
    "        self.photoViewer.setPixmap(QPixmap(file_path))\n",
    "        \n",
    "    def set_path(self, file_path):\n",
    "        self.img_path = file_path\n",
    "    \n",
    "    def get_path(self):\n",
    "        return self.img_path\n",
    "        \n",
    "    def quit(self):\n",
    "        self.close()\n",
    "        \n",
    "    def keyPressEvent(self, event):\n",
    "        if event.key() == Qt.Key_Return:\n",
    "            self.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f83a15fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showdialog(image_desc):\n",
    "    msg = QMessageBox()\n",
    "    msg.setIcon(QMessageBox.Information)\n",
    "    msg.setWindowTitle(\"Image description\")\n",
    "    msg.setText(image_desc)\n",
    "    msg.exec_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334ca35f",
   "metadata": {},
   "source": [
    "# Generating Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "339c3e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18e5724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "from tensorflow.keras.models import load_model\n",
    "final_model = load_model(base_path+'\\\\models\\model_18.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fc0dea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordtoix = pickle.load(open(base_path+'\\\\wordtoint.pickle', 'rb'))\n",
    "ixtoword = pickle.load(open(base_path+'\\\\inttoword.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "745ec82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ea9b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for one image\n",
    "def input_img(img_path):\n",
    "    img_arr = process_img(img_path)\n",
    "    img_vec = encode_feature(img_arr)\n",
    "    return img_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64a46dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_search(img_feature, trained_model, max_len):\n",
    "    start = 'startseq'\n",
    "    img_feature = np.expand_dims(img_feature,axis=0)\n",
    "    for i in range(max_len):\n",
    "        seq = [wordtoix[word] for word in start.split() if word in wordtoix]\n",
    "        seq = pad_sequences([seq], maxlen = max_len)\n",
    "        yhat = trained_model.predict([img_feature, seq])\n",
    "        yhat = np.argmax(yhat)\n",
    "        word = ixtoword[yhat]\n",
    "        start += ' ' + word\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "    final = start.split()\n",
    "    final = final[1:-1]\n",
    "    final = ' '.join(final)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf2de71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_caption():\n",
    "    if not QApplication.instance():\n",
    "        app = QApplication(sys.argv)\n",
    "    else:\n",
    "        app = QApplication.instance()\n",
    "    window = AppDemo()\n",
    "    window.show()\n",
    "    app.exec_()\n",
    "    image_path = window.get_path()\n",
    "    with tf.device('/GPU:0'):\n",
    "        img_feature = input_img(image_path)\n",
    "        # generate description\n",
    "        image_desc = greedy_search(img_feature, final_model, max_len)\n",
    "    showdialog(image_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b0710ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_caption()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e6638c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37850fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
